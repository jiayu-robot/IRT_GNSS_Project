{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f5204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Config] 正在使用的设备: cpu ---\n"
     ]
    }
   ],
   "source": [
    "# 模型的数据加载与预处理\n",
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "from tqdm import tqdm\n",
    "from utility_uad_svm import load_data, make_sequences, create_dataloaders, SeqDataset\n",
    "\n",
    "#for key in config.csv_path:\n",
    "#    print(f\"数据集{key}路径: {config.csv_path[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5cc5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "\n",
    "# === 1. 定义梯度反转层 (GRL) ===\n",
    "class GradientReverseFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        # 在前向传播中，不改变输入，但保存 alpha 用于反向传播\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # 在反向传播中，将梯度乘以 -alpha\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        return output, None\n",
    "\n",
    "def grad_reverse(x, alpha):\n",
    "    return GradientReverseFunction.apply(x, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e2818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(G_f, G_y, G_d, dl_src, dl_tgt, opt_G, opt_D, loss_cls_fn, loss_dom_fn, device, epoch, total_epochs):\n",
    "    \"\"\"\n",
    "    参数主要变更:\n",
    "    1. 移除了 grl 参数 (我们直接在函数里用 grad_reverse)\n",
    "    2. 增加了 epoch 和 total_epochs (用于计算进度 p)\n",
    "    \"\"\"\n",
    "    G_f.train()\n",
    "    G_y.train()\n",
    "    G_d.train()\n",
    "    \n",
    "    total_loss_cls = 0.0\n",
    "    total_loss_dom = 0.0\n",
    "    \n",
    "    # 获取批次总数用于计算进度\n",
    "    len_dataloader = min(len(dl_src), len(dl_tgt)) \n",
    "    iter_src = iter(dl_src)\n",
    "    iter_tgt = iter(dl_tgt) # 同时也建议把 target 做成 iter，防止长度不一致报错\n",
    "\n",
    "    # TQDM 进度条\n",
    "    from tqdm import tqdm\n",
    "    pbar = tqdm(range(len_dataloader), desc=f\"Epoch {epoch+1}/{total_epochs}\", leave=False)\n",
    "\n",
    "    for batch_idx in pbar:\n",
    "        # ----------------------------------------------------\n",
    "        # --- 0. 计算动态 Alpha (核心修改) ---\n",
    "        # ----------------------------------------------------\n",
    "        # p: 训练进度，从 0 慢慢变到 1\n",
    "        p = float(batch_idx + epoch * len_dataloader) / (total_epochs * len_dataloader)\n",
    "        # alpha: 梯度反转强度，从 0 慢慢变到 1\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "        \n",
    "        # 更新进度条显示当前的 alpha\n",
    "        pbar.set_postfix({'alpha': f'{alpha:.4f}'})\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # --- 步骤 A & B: 加载数据 ---\n",
    "        # ----------------------------------------------------\n",
    "        try:\n",
    "            data_src = next(iter_src)\n",
    "            data_tgt = next(iter_tgt)\n",
    "        except StopIteration:\n",
    "            # 防止迭代器耗尽\n",
    "            iter_src = iter(dl_src)\n",
    "            iter_tgt = iter(dl_tgt)\n",
    "            data_src = next(iter_src)\n",
    "            data_tgt = next(iter_tgt)\n",
    "\n",
    "        X_src_batch, y_src_batch = data_src[0], data_src[1]\n",
    "        X_tgt_batch = data_tgt[0] # target 域通常没有 label 或不用 label\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # --- 步骤 C: NaN/INF 安全检查 & 设备传输 ---\n",
    "        # ----------------------------------------------------\n",
    "        X_src = X_src_batch.to(device)\n",
    "        y_src = y_src_batch.to(device)\n",
    "        X_tgt = X_tgt_batch.to(device)\n",
    "\n",
    "        if torch.isnan(X_src).any() or torch.isnan(X_tgt).any():\n",
    "            continue # 跳过坏数据\n",
    "\n",
    "        # ====================================================\n",
    "        # 第一阶段：优化 G_f (特征提取) 和 G_y (分类)\n",
    "        # ====================================================\n",
    "        opt_G.zero_grad() # 清空 G_f and G_y 的梯度\n",
    "        \n",
    "        # 1. 特征提取\n",
    "        feat_src = G_f(X_src)\n",
    "        feat_tgt = G_f(X_tgt)\n",
    "\n",
    "        # 2. 类别分类损失 (仅源域)\n",
    "        logits_cls = G_y(feat_src)\n",
    "        loss_cls = loss_cls_fn(logits_cls, y_src)\n",
    "\n",
    "        # 3. 域判别损失 (用于对抗)\n",
    "        # [关键点] 这里应用 动态 GRL\n",
    "        feat_src_adv = grad_reverse(feat_src, alpha)\n",
    "        feat_tgt_adv = grad_reverse(feat_tgt, alpha)\n",
    "        \n",
    "        # 拼接用于判别器\n",
    "        feat_combined_adv = torch.cat((feat_src_adv, feat_tgt_adv), dim=0)\n",
    "        \n",
    "        # 准备域标签 (0: Source, 1: Target)\n",
    "        domain_label_src = torch.zeros(feat_src.size(0), dtype=torch.long, device=device)\n",
    "        domain_label_tgt = torch.ones(feat_tgt.size(0), dtype=torch.long, device=device)\n",
    "        domain_label_combined = torch.cat((domain_label_src, domain_label_tgt), dim=0)\n",
    "\n",
    "        # 通过判别器\n",
    "        logits_dom_adv = G_d(feat_combined_adv)\n",
    "        loss_dom_adv = loss_dom_fn(logits_dom_adv, domain_label_combined)\n",
    "\n",
    "        # 总损失：分类损失 + 域对抗损失\n",
    "        # 注意：因为用了 grad_reverse，backward 时 loss_dom_adv 的梯度会自动反转\n",
    "        # 所以这里是用加号 (+)\n",
    "        loss_total_G = loss_cls + loss_dom_adv\n",
    "        loss_total_G.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "        # ====================================================\n",
    "        # 第二阶段：优化 G_d (域判别器)\n",
    "        # ====================================================\n",
    "        # 这一步是为了让 G_d 尽可能准，不涉及 GRL，也不更新 G_f\n",
    "        opt_D.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feat_src_fixed = G_f(X_src)\n",
    "            feat_tgt_fixed = G_f(X_tgt)\n",
    "        \n",
    "        feat_combined_fixed = torch.cat((feat_src_fixed, feat_tgt_fixed), dim=0)\n",
    "        logits_dom_fixed = G_d(feat_combined_fixed)\n",
    "        loss_dom_D = loss_dom_fn(logits_dom_fixed, domain_label_combined)\n",
    "        \n",
    "        loss_dom_D.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # --- 记录数据 ---\n",
    "        # ----------------------------------------------------\n",
    "        total_loss_cls += loss_cls.item()\n",
    "        total_loss_dom += loss_dom_D.item()\n",
    "\n",
    "    return total_loss_cls / len_dataloader, total_loss_dom / len_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45314c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. 基础设置\n",
    "# ==========================================\n",
    "# 读取配置中的 ID 和 路径\n",
    "SRC_IDS = config.SRC_IDS \n",
    "TGT_ID = config.TGT_ID    \n",
    "CSV_PATHS = config.CSV_PATHS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1baa68d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [Main] 正在使用设备: cpu ---\n",
      "\n",
      "--- [Main - 步骤 1-3] 正在加载并准备数据... ---\n",
      " -> 正在加载所有源域数据 (用于计算标准化统计量)...\n",
      " -> 源域数据加载完成，总行数: 710063\n",
      "\n",
      "[Standardization] 正在计算源域统计量并标准化 (Fit & Transform)...\n",
      " -> 特征均值 (前5个): [ 85.70710577  28.48481672  -0.32090063 -17.25298188   0.3716304 ]\n",
      " -> 特征方差 (前5个): [4.28103153e+03 4.20093196e+02 1.05978683e+03 2.84691761e+06\n",
      " 2.33521247e-01]\n",
      " -> Scaler 已保存至: c:\\Users\\yangj\\Desktop\\GNSS-main\\GNSS-main\\Transfer Learning\\SVM\\checkpoints\\global_scaler.pkl\n",
      " -> 正在制作源域序列 (逐个Case标准化并切片)...\n",
      "  - X 形状: (91655, 5, 5), y 形状: (91655,)\n",
      "  - X 形状: (91655, 5, 5), y 形状: (91655,)\n",
      "  - X 形状: (79792, 5, 5), y 形状: (79792,)\n",
      "  - X 形状: (79830, 5, 5), y 形状: (79830,)\n",
      "  - X 形状: (91654, 5, 5), y 形状: (91654,)\n",
      "  - X 形状: (91655, 5, 5), y 形状: (91655,)\n",
      "  - X 形状: (91655, 5, 5), y 形状: (91655,)\n",
      "  - X 形状: (91655, 5, 5), y 形状: (91655,)\n",
      " -> 源域序列制作完成。X_src: (709551, 5, 5)\n",
      " -> 正在处理目标域数据...\n",
      "[load_data] 正在加载目标域数据: 0\n",
      "[load_data] 目标域加载完成。形状: (12614, 14)\n",
      "[load_data] 注：源域数据将在 'create_all_sequences' 中逐个加载以保证时序独立性。\n",
      "  - X 形状: (12538, 5, 5)\n",
      "\n",
      "--- [DataLoaders] 正在创建 DataLoaders... ---\n",
      " f - 源域 (仿真) 加载器: 709551 个样本, 11086 个批次。\n",
      " f - 目标域 (真实) 加载器: 12538 个样本, 195 个批次。\n",
      "--- [Main - 步骤 1-3] 数据准备完毕。---\n",
      "\n",
      "--- [Main - 步骤 4] 正在搭建模型框架... ---\n",
      " - 模型已创建。\n",
      "\n",
      "--- [Main - 步骤 6] !!! 开始训练 !!! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] 完成. Cls Loss: 0.4176 | Dom Loss: 0.6569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] 完成. Cls Loss: 0.3632 | Dom Loss: 0.6399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] 完成. Cls Loss: 0.3354 | Dom Loss: 0.6984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] 完成. Cls Loss: 0.3006 | Dom Loss: 0.7080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] 完成. Cls Loss: 0.2832 | Dom Loss: 0.6880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] 完成. Cls Loss: 0.2804 | Dom Loss: 0.6899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] 完成. Cls Loss: 0.2713 | Dom Loss: 0.6786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] 完成. Cls Loss: 0.2686 | Dom Loss: 0.6793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] 完成. Cls Loss: 0.2673 | Dom Loss: 0.6749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] 完成. Cls Loss: 0.2553 | Dom Loss: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] 完成. Cls Loss: 0.2620 | Dom Loss: 0.6699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] 完成. Cls Loss: 0.2679 | Dom Loss: 0.6698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] 完成. Cls Loss: 0.2559 | Dom Loss: 0.6699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] 完成. Cls Loss: 0.2643 | Dom Loss: 0.6783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] 完成. Cls Loss: 0.2626 | Dom Loss: 0.6810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] 完成. Cls Loss: 0.2561 | Dom Loss: 0.6821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] 完成. Cls Loss: 0.2451 | Dom Loss: 0.6752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] 完成. Cls Loss: 0.2545 | Dom Loss: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] 完成. Cls Loss: 0.2510 | Dom Loss: 0.6735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] 完成. Cls Loss: 0.2529 | Dom Loss: 0.6809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] 完成. Cls Loss: 0.2460 | Dom Loss: 0.6718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] 完成. Cls Loss: 0.2483 | Dom Loss: 0.6752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] 完成. Cls Loss: 0.2471 | Dom Loss: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] 完成. Cls Loss: 0.2480 | Dom Loss: 0.6766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] 完成. Cls Loss: 0.2497 | Dom Loss: 0.6721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] 完成. Cls Loss: 0.2434 | Dom Loss: 0.6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] 完成. Cls Loss: 0.2369 | Dom Loss: 0.6621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] 完成. Cls Loss: 0.2414 | Dom Loss: 0.6676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] 完成. Cls Loss: 0.2441 | Dom Loss: 0.6740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] 完成. Cls Loss: 0.2447 | Dom Loss: 0.6677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] 完成. Cls Loss: 0.2358 | Dom Loss: 0.6666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] 完成. Cls Loss: 0.2381 | Dom Loss: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] 完成. Cls Loss: 0.2404 | Dom Loss: 0.6683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] 完成. Cls Loss: 0.2420 | Dom Loss: 0.6675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] 完成. Cls Loss: 0.2417 | Dom Loss: 0.6628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] 完成. Cls Loss: 0.2379 | Dom Loss: 0.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] 完成. Cls Loss: 0.2424 | Dom Loss: 0.6683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] 完成. Cls Loss: 0.2474 | Dom Loss: 0.6842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] 完成. Cls Loss: 0.2455 | Dom Loss: 0.7017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] 完成. Cls Loss: 0.2393 | Dom Loss: 0.6977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] 完成. Cls Loss: 0.2392 | Dom Loss: 0.6911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] 完成. Cls Loss: 0.2382 | Dom Loss: 0.6948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] 完成. Cls Loss: 0.2327 | Dom Loss: 0.6857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] 完成. Cls Loss: 0.2325 | Dom Loss: 0.6911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] 完成. Cls Loss: 0.2418 | Dom Loss: 0.6984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] 完成. Cls Loss: 0.2310 | Dom Loss: 0.6911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] 完成. Cls Loss: 0.2361 | Dom Loss: 0.6859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] 完成. Cls Loss: 0.2331 | Dom Loss: 0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] 完成. Cls Loss: 0.2259 | Dom Loss: 0.6910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] 完成. Cls Loss: 0.2301 | Dom Loss: 0.6838\n",
      "\n",
      "--- [Main - 步骤 6] !!! 训练完成 !!! ---\n",
      "\n",
      "--- [Main - 步骤 7] 正在保存最终模型... ---\n",
      " - 特征提取器 (G_f) 已保存到: c:\\Users\\yangj\\Desktop\\GNSS-main\\GNSS-main\\Transfer Learning\\SVM\\checkpoints\\G_f_final.pth\n",
      " - 标签分类器 (G_y) 已保存到: c:\\Users\\yangj\\Desktop\\GNSS-main\\GNSS-main\\Transfer Learning\\SVM\\checkpoints\\G_y_final.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models import LSTMFeatureExtractor, LabelClassifier, DomainDiscriminator\n",
    "from utility_uad_svm import load_data, make_sequences, create_dataloaders, train_lstm_dann_standardization, lstm_standardization_train_pre_svm\n",
    "\n",
    "# 引入训练循环函数 (假设它定义在同一个文件或 utility 中，如果是在本文件定义的，请保持不动)\n",
    "# from your_file import train_loop \n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    [Main 函数详解]\n",
    "    这是整个程序的控制中心。\n",
    "    \"\"\"\n",
    "    # 设置计算设备 (GPU/CPU)\n",
    "    device = torch.device(config.DEVICE)\n",
    "    print(f\"--- [Main] 正在使用设备: {device} ---\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # 2. 数据准备 (Data Pipeline)\n",
    "    # ==========================================\n",
    "    print(\"\\n--- [Main - 步骤 1-3] 正在加载并准备数据... ---\")\n",
    "    \n",
    "    # -------------------------------------------------------------\n",
    "    # [修复核心] 1. 加载所有源域数据以构建 df_src_all\n",
    "    # -------------------------------------------------------------\n",
    "    print(\" -> 正在加载所有源域数据 (用于计算标准化统计量)...\")\n",
    "    df_src_list = []\n",
    "    # 遍历所有源域 ID\n",
    "    for src_id in config.SRC_IDS:\n",
    "        path = config.CSV_PATHS[src_id]\n",
    "        if os.path.exists(path):\n",
    "            df_tmp = pd.read_csv(path)\n",
    "            df_src_list.append(df_tmp)\n",
    "        else:\n",
    "            print(f\"警告: 找不到文件 {path}\")\n",
    "            \n",
    "    if not df_src_list:\n",
    "        print(\"错误: 没有加载到任何源域数据！\")\n",
    "        return\n",
    "\n",
    "    # 合并成一个大 DataFrame，这就是缺失的 df_src_all\n",
    "    df_src_all = pd.concat(df_src_list, ignore_index=True)\n",
    "    print(f\" -> 源域数据加载完成，总行数: {len(df_src_all)}\")\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # 2. 训练标准化器 (Fit & Save Scaler)\n",
    "    # -------------------------------------------------------------\n",
    "    # 这里调用第一个辅助函数：计算均值方差并保存 Scaler\n",
    "    # 注意：这里的 df_src_all 只是用来计算参数的\n",
    "    train_lstm_dann_standardization(\n",
    "        df_src_all, \n",
    "        config.FEATURES, \n",
    "        config.MODEL_SAVE_DIR\n",
    "    )\n",
    "    # 注意：执行完这一步，config.MODEL_SAVE_DIR 下会生成 global_scaler.pkl\n",
    "    \n",
    "    # -------------------------------------------------------------\n",
    "    # 3. 制作源域序列 (Load -> Standardize -> Sequence)\n",
    "    # -------------------------------------------------------------\n",
    "    print(\" -> 正在制作源域序列 (逐个Case标准化并切片)...\")\n",
    "    all_X_list = []\n",
    "    all_y_list = []\n",
    "    \n",
    "    # 重新遍历文件，这次是为了制作序列，同时应用刚才保存的 Scaler\n",
    "    for src_id in config.SRC_IDS:\n",
    "        path = config.CSV_PATHS[src_id]\n",
    "        df_case = pd.read_csv(path)\n",
    "        \n",
    "        # [关键] 加载刚才存好的 Scaler 并应用标准化 (Transform only)\n",
    "        # 这样确保每个 Case 都是用全局标准处理的\n",
    "        df_case = lstm_standardization_train_pre_svm(\n",
    "            df_case,\n",
    "            config.FEATURES,\n",
    "            config.MODEL_SAVE_DIR\n",
    "        )\n",
    "        \n",
    "        # 制作序列\n",
    "        X_c, y_c = make_sequences(\n",
    "            df=df_case, \n",
    "            features=config.FEATURES, \n",
    "            target=config.TARGET_COL,\n",
    "            seq_len=config.SEQ_LEN, \n",
    "            step=config.STEP\n",
    "        )\n",
    "        \n",
    "        if len(X_c) > 0:\n",
    "            all_X_list.append(X_c)\n",
    "            all_y_list.append(y_c)\n",
    "\n",
    "    if not all_X_list:\n",
    "        print(\"错误: 源域序列生成失败。\")\n",
    "        return\n",
    "\n",
    "    X_src = np.concatenate(all_X_list, axis=0)\n",
    "    y_src = np.concatenate(all_y_list, axis=0)\n",
    "    print(f\" -> 源域序列制作完成。X_src: {X_src.shape}\")\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # 4. 处理目标域数据 (Load -> Standardize -> Sequence)\n",
    "    # -------------------------------------------------------------\n",
    "    print(\" -> 正在处理目标域数据...\")\n",
    "    _, df_tgt = load_data(config.SRC_IDS, config.TGT_ID, config.CSV_PATHS)\n",
    "    \n",
    "    if df_tgt is None: \n",
    "        print(\"错误：目标域数据加载失败。\")\n",
    "        return\n",
    "\n",
    "    # 清洗 Inf/NaN\n",
    "    df_tgt = df_tgt.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    # [关键] 对目标域应用同样的标准化\n",
    "    df_tgt = lstm_standardization_train_pre_svm(\n",
    "        df_tgt, \n",
    "        config.FEATURES, \n",
    "        config.MODEL_SAVE_DIR\n",
    "    )\n",
    "    \n",
    "    # 制作序列 (Target=None)\n",
    "    X_tgt = make_sequences(\n",
    "        df=df_tgt, \n",
    "        features=config.FEATURES, \n",
    "        target=None, \n",
    "        seq_len=config.SEQ_LEN, \n",
    "        step=config.STEP\n",
    "    )\n",
    "    \n",
    "    if X_src is None or X_tgt is None: \n",
    "        print(\"错误：序列生成失败 (X_src 或 X_tgt 为空)。\")\n",
    "        return\n",
    "        \n",
    "    # -------------------------------------------------------------\n",
    "    # 5. 创建 DataLoader\n",
    "    # -------------------------------------------------------------\n",
    "    dl_src, dl_tgt = create_dataloaders(X_src, y_src, X_tgt, config.BATCH_SIZE)\n",
    "    if dl_src is None or dl_tgt is None: return\n",
    "    \n",
    "    print(\"--- [Main - 步骤 1-3] 数据准备完毕。---\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # 3. 搭建模型 (Model Setup)\n",
    "    # ==========================================\n",
    "    print(\"\\n--- [Main - 步骤 4] 正在搭建模型框架... ---\")\n",
    "    \n",
    "    # G_f: 特征提取器\n",
    "    G_f = LSTMFeatureExtractor(\n",
    "        input_size=config.LSTM_INPUT_SIZE,   \n",
    "        hidden_size=config.LSTM_HIDDEN_SIZE, \n",
    "        num_layers=config.LSTM_NUM_LAYERS,   \n",
    "        dropout=config.LSTM_DROPOUT\n",
    "    ).to(device)\n",
    "\n",
    "    # G_y: 标签分类器\n",
    "    G_y = LabelClassifier(\n",
    "        input_size=config.LSTM_HIDDEN_SIZE, \n",
    "        num_classes=config.NUM_CLASSES,      \n",
    "        hidden_dim=config.CLASSIFIER_HIDDEN_DIM\n",
    "    ).to(device)\n",
    "\n",
    "    # G_d: 域判别器\n",
    "    G_d = DomainDiscriminator(\n",
    "        input_size=config.LSTM_HIDDEN_SIZE, \n",
    "        hidden_dim=config.CLASSIFIER_HIDDEN_DIM\n",
    "    ).to(device)\n",
    "    \n",
    "    print(\" - 模型已创建。\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. 损失函数与优化器\n",
    "    # ==========================================\n",
    "    class_weights = torch.tensor([4.0, 1.0]).to(device) # 根据你的情况调整\n",
    "    loss_cls_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    loss_dom_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    opt_G = optim.Adam(list(G_f.parameters()) + list(G_y.parameters()), lr=config.LEARNING_RATE_G)\n",
    "    opt_D = optim.Adam(G_d.parameters(), lr=config.LEARNING_RATE_D)\n",
    "    \n",
    "    # ==========================================\n",
    "    # 5. 训练循环 (Training Loop)\n",
    "    # ==========================================\n",
    "    print(\"\\n--- [Main - 步骤 6] !!! 开始训练 !!! ---\") \n",
    "    \n",
    "    final_loss_cls = 0.0\n",
    "    final_loss_dom = 0.0\n",
    "    \n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        # 注意：这里需要你确保 train_loop 函数在作用域内\n",
    "        # 如果 train_loop 在该文件外部定义，需要正确 import\n",
    "        avg_loss_cls, avg_loss_dom = train_loop(\n",
    "            G_f, G_y, G_d,          \n",
    "            dl_src, dl_tgt,         \n",
    "            opt_G, opt_D,           \n",
    "            loss_cls_fn, loss_dom_fn, \n",
    "            device,                 \n",
    "            epoch,                  \n",
    "            config.NUM_EPOCHS       \n",
    "        )\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{config.NUM_EPOCHS}] 完成. Cls Loss: {avg_loss_cls:.4f} | Dom Loss: {avg_loss_dom:.4f}\")\n",
    "        final_loss_cls = avg_loss_cls\n",
    "        final_loss_dom = avg_loss_dom\n",
    "        \n",
    "    print(\"\\n--- [Main - 步骤 6] !!! 训练完成 !!! ---\")\n",
    "    \n",
    "    # ==========================================\n",
    "    # 6. 保存模型\n",
    "    # ==========================================\n",
    "    print(\"\\n--- [Main - 步骤 7] 正在保存最终模型... ---\") \n",
    "    os.makedirs(config.MODEL_SAVE_DIR, exist_ok=True) \n",
    "    \n",
    "    g_f_path = os.path.join(config.MODEL_SAVE_DIR, \"G_f_final.pth\")\n",
    "    g_y_path = os.path.join(config.MODEL_SAVE_DIR, \"G_y_final.pth\")\n",
    "    \n",
    "    torch.save(G_f.state_dict(), g_f_path)\n",
    "    torch.save(G_y.state_dict(), g_y_path)\n",
    "    \n",
    "    print(f\" - 特征提取器 (G_f) 已保存到: {g_f_path}\")\n",
    "    print(f\" - 标签分类器 (G_y) 已保存到: {g_y_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79a025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import LSTMFeatureExtractor, LabelClassifier, DomainDiscriminator, GRL_Layer\n",
    "# import torch.optim as optim\n",
    "# from utility_uad_svm  import load_data, make_sequences, create_dataloaders,create_all_sequences\n",
    "# from utility_uad_svm import train_lstm_dann_standardization, lstm_standardization_train_pre_svm\n",
    "# def main():\n",
    "#     \"\"\"\n",
    "#     [Main 函数详解]\n",
    "#     这是整个程序的控制中心。\n",
    "#     \"\"\"\n",
    "#     # ... 在 main 函数里 ...\n",
    "\n",
    "#     # 1. 对源域 (Fit + Save)\n",
    "#     df_src_all = train_lstm_dann_standardization(\n",
    "#         df_src_all, \n",
    "#         config.FEATURES, \n",
    "#         config.MODEL_SAVE_DIR\n",
    "#     )\n",
    "\n",
    "#     # 2. 对目标域 (Transform only - 虽然 DANN 训练时不一定要用到目标域的特征值本身，但保持一致比较好)\n",
    "#     df_tgt = lstm_standardization_train_pre_svm(\n",
    "#         df_tgt, \n",
    "#         config.FEATURES, \n",
    "#         config.MODEL_SAVE_DIR\n",
    "#     )\n",
    "    \n",
    "#     # 设置计算设备 (GPU/CPU)\n",
    "#     device = torch.device(config.DEVICE)\n",
    "#     print(f\"--- [Main] 正在使用设备: {device} ---\")\n",
    "    \n",
    "#     # ==========================================\n",
    "#     # 2. 数据准备 (Data Pipeline)\n",
    "#     # ==========================================\n",
    "#     print(\"\\n--- [Main - 步骤 1-3] 正在加载并准备数据... ---\")\n",
    "    \n",
    "#     # 2a. 加载原始 CSV 数据\n",
    "#     df_src, df_tgt = load_data(SRC_IDS, TGT_ID, CSV_PATHS)\n",
    "#     # if df_src is None or df_tgt is None: return\n",
    "#     if df_tgt is None: \n",
    "#         print(\"错误：目标域数据加载失败。\")\n",
    "#         return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # 2b. 简单的 NaN/Inf 清洗 (针对目标域)\n",
    "#     if df_tgt.isnull().values.any():\n",
    "#         print(f\"【警告】目标域有 NaN，正在填充 0...\")\n",
    "#         df_tgt = df_tgt.fillna(0)\n",
    "#     if (df_tgt == np.inf).any().any() or (df_tgt == -np.inf).any().any():\n",
    "#         print(\"【警告】目标域有 INF，正在替换为 0...\")\n",
    "#         df_tgt = df_tgt.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "#     # 2c. 制作时间序列 (Sequences)\n",
    "#     # 这里调用 create_all_sequences，它内部会调用 make_sequences\n",
    "\n",
    "#     X_src, y_src, X_tgt = create_all_sequences(df_src, df_tgt, config)\n",
    "#     # [新增] 安全检查：确保序列真的生成了\n",
    "#     if X_src is None or X_tgt is None: \n",
    "#         print(\"错误：序列生成失败 (X_src 或 X_tgt 为空)。\")\n",
    "#         return\n",
    "#     # if X_src is None or X_tgt is None: return\n",
    "        \n",
    "#     # 2d. 创建 DataLoader (投喂器)\n",
    "#     # 这一步把 numpy 数组变成了 PyTorch 可以批量读取的对象\n",
    "#     dl_src, dl_tgt = create_dataloaders(X_src, y_src, X_tgt, config.BATCH_SIZE)\n",
    "#     if dl_src is None or dl_tgt is None: return\n",
    "    \n",
    "#     print(\"--- [Main - 步骤 1-3] 数据准备完毕。---\")\n",
    "    \n",
    "#     # ==========================================\n",
    "#     # 3. 搭建模型 (Model Setup)\n",
    "#     # ==========================================\n",
    "#     print(\"\\n--- [Main - 步骤 4] 正在搭建模型框架... ---\")\n",
    "    \n",
    "#     # (4a) G_f: 特征提取器\n",
    "#     # 假设您修改后的 __init__ 默认 final_feature_dim=128，或者跟 hidden_size 一样\n",
    "#     G_f = LSTMFeatureExtractor(\n",
    "#         input_size=config.LSTM_INPUT_SIZE,   # 例如 5 (根据特征数量)\n",
    "#         hidden_size=config.LSTM_HIDDEN_SIZE, # 例如 128 (内部 LSTM 单元数)\n",
    "#         num_layers=config.LSTM_NUM_LAYERS,   # 例如 2\n",
    "#         dropout=config.LSTM_DROPOUT\n",
    "#         # 如果您代码里加了 final_feature_dim 参数，这里最好显式传一下，例如：\n",
    "#         # final_feature_dim=config.LSTM_HIDDEN_SIZE \n",
    "#     ).to(device)\n",
    "\n",
    "#     # (4b) G_y: 标签分类器\n",
    "#     # 接收 G_f 的输出。只要 G_f 输出是 128，这里 input_size=128 就没问题\n",
    "#     G_y = LabelClassifier(\n",
    "#         input_size=config.LSTM_HIDDEN_SIZE, \n",
    "#         num_classes=config.NUM_CLASSES,      # 例如 2 (好/坏)\n",
    "#         hidden_dim=config.CLASSIFIER_HIDDEN_DIM\n",
    "#     ).to(device)\n",
    "\n",
    "#     # (4c) G_d: 域判别器\n",
    "#     # 接收 G_f 的输出。道理同上。\n",
    "#     G_d = DomainDiscriminator(\n",
    "#         input_size=config.LSTM_HIDDEN_SIZE, \n",
    "#         hidden_dim=config.CLASSIFIER_HIDDEN_DIM\n",
    "#     ).to(device)\n",
    "\n",
    "#     # (4d) 【重要修改】删除 GRL 层的实例化\n",
    "#     # grl = GRL_Layer(...)  <--- 删除这行！\n",
    "#     # 原因：我们在 train_loop 里使用动态计算的 alpha，不需要这个固定的层了。\n",
    "    \n",
    "#     print(\" - G_f, G_y, G_d 模型已在设备上创建。\")\n",
    "\n",
    "#     # ==========================================\n",
    "#     # 4. 损失函数与优化器\n",
    "#     # ==========================================\n",
    "#     print(\"\\n--- [Main - 步骤 5] 正在搭建损失函数和优化器... ---\")\n",
    "\n",
    "#     # (5a) 损失函数\n",
    "#     class_weights = torch.tensor([4.0, 1.0]).to(device) \n",
    "#     loss_cls_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "#     loss_dom_fn = nn.CrossEntropyLoss() # 域分类通常是平衡的，不需要加权\n",
    "\n",
    "#     # (5b) 优化器\n",
    "#     # 优化 G_f 和 G_y\n",
    "#     opt_G = optim.Adam(\n",
    "#         list(G_f.parameters()) + list(G_y.parameters()),\n",
    "#         lr=config.LEARNING_RATE_G\n",
    "#     )\n",
    "#     # 独立优化 G_d\n",
    "#     opt_D = optim.Adam(\n",
    "#         G_d.parameters(),\n",
    "#         lr=config.LEARNING_RATE_D\n",
    "#     )\n",
    "    \n",
    "#     print(\" - 损失函数和优化器已定义。\")\n",
    "#     print(\"--- [Main - 步骤 4 & 5] 模型搭建完毕。---\")\n",
    "    \n",
    "#     # ==========================================\n",
    "#     # 5. 训练循环 (Training Loop)\n",
    "#     # ==========================================\n",
    "#     print(\"\\n--- [Main - 步骤 6] !!! 开始训练 !!! ---\") \n",
    "    \n",
    "#     final_loss_cls = 0.0\n",
    "#     final_loss_dom = 0.0\n",
    "    \n",
    "#     for epoch in range(config.NUM_EPOCHS):\n",
    "        \n",
    "#         # 【关键修改】调用 train_loop\n",
    "#         # 1. 删除了 grl 参数\n",
    "#         # 2. 传入了 epoch 和 config.NUM_EPOCHS 用于计算动态 alpha\n",
    "#         avg_loss_cls, avg_loss_dom = train_loop(\n",
    "#             G_f, G_y, G_d,          # 模型\n",
    "#             dl_src, dl_tgt,         # 数据\n",
    "#             opt_G, opt_D,           # 优化器\n",
    "#             loss_cls_fn, loss_dom_fn, # 损失函数\n",
    "#             device,                 # 设备\n",
    "#             epoch,                  # 当前轮数 (新!)\n",
    "#             config.NUM_EPOCHS       # 总轮数 (新!)\n",
    "#         )\n",
    "        \n",
    "#         # 打印进度 (train_loop 里已经有进度条，这里打印 Epoch 总结)\n",
    "#         print(f\"Epoch [{epoch+1}/{config.NUM_EPOCHS}] 完成. Cls Loss: {avg_loss_cls:.4f} | Dom Loss: {avg_loss_dom:.4f}\")\n",
    "        \n",
    "#         final_loss_cls = avg_loss_cls\n",
    "#         final_loss_dom = avg_loss_dom\n",
    "        \n",
    "#         # (可选) 在这里可以加一个 save_checkpoint 的逻辑\n",
    "        \n",
    "#     print(\"\\n--- [Main - 步骤 6] !!! 训练完成 !!! ---\")\n",
    "#     print(f\" - 最终分类损失 (Loss_cls): {final_loss_cls:.4f}\")\n",
    "#     print(f\" - 最终域损失 (Loss_dom): {final_loss_dom:.4f}\")\n",
    "    \n",
    "#     # ==========================================\n",
    "#     # 6. 保存模型\n",
    "#     # ==========================================\n",
    "#     print(\"\\n--- [Main - 步骤 7] 正在保存最终模型... ---\") \n",
    "#     os.makedirs(config.MODEL_SAVE_DIR, exist_ok=True) \n",
    "    \n",
    "#     g_f_path = os.path.join(config.MODEL_SAVE_DIR, \"G_f_final.pth\")\n",
    "#     g_y_path = os.path.join(config.MODEL_SAVE_DIR, \"G_y_final.pth\")\n",
    "    \n",
    "#     torch.save(G_f.state_dict(), g_f_path)\n",
    "#     torch.save(G_y.state_dict(), g_y_path)\n",
    "    \n",
    "#     print(f\" - 特征提取器 (G_f) 已保存到: {g_f_path}\")\n",
    "#     print(f\" - 标签分类器 (G_y) 已保存到: {g_y_path}\")\n",
    "\n",
    "# # 别忘了运行 main\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
