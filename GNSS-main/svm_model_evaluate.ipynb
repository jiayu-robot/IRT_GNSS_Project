{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "738c3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 绘图相关的库\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import single_point_positioning, ecef_to_llh, llh_to_enu, plot_trajectory, weighted_single_point_positioning\n",
    "from eval_utils import multi_constellation_spp, weighted_multi_constellation_spp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ab75b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从 'RWD_20250422/D1T4/tgt_data_with_single_svm_predictions.csv' 加载观测数据...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gps_time</th>\n",
       "      <th>satellite_id</th>\n",
       "      <th>sv_id</th>\n",
       "      <th>pseudorange</th>\n",
       "      <th>doppler_shift</th>\n",
       "      <th>cn0</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>elevation</th>\n",
       "      <th>pseudorange_residual</th>\n",
       "      <th>pseudorange_corrected_cb</th>\n",
       "      <th>sat_px</th>\n",
       "      <th>sat_py</th>\n",
       "      <th>sat_pz</th>\n",
       "      <th>sat_type</th>\n",
       "      <th>predicted_multipath</th>\n",
       "      <th>svm_decision_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.429365e+09</td>\n",
       "      <td>G01</td>\n",
       "      <td>1</td>\n",
       "      <td>2.371945e+07</td>\n",
       "      <td>-3039.00801</td>\n",
       "      <td>42.97546</td>\n",
       "      <td>262.63392</td>\n",
       "      <td>15.78166</td>\n",
       "      <td>-0.46956</td>\n",
       "      <td>2.409778e+07</td>\n",
       "      <td>1.527411e+07</td>\n",
       "      <td>-2.033628e+07</td>\n",
       "      <td>7.613143e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.429365e+09</td>\n",
       "      <td>G02</td>\n",
       "      <td>2</td>\n",
       "      <td>2.160127e+07</td>\n",
       "      <td>-1837.17348</td>\n",
       "      <td>45.60996</td>\n",
       "      <td>277.05302</td>\n",
       "      <td>44.45788</td>\n",
       "      <td>0.04192</td>\n",
       "      <td>2.185358e+07</td>\n",
       "      <td>1.592333e+07</td>\n",
       "      <td>-1.252732e+07</td>\n",
       "      <td>1.739108e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.429365e+09</td>\n",
       "      <td>G08</td>\n",
       "      <td>8</td>\n",
       "      <td>2.007511e+07</td>\n",
       "      <td>-926.01404</td>\n",
       "      <td>48.38570</td>\n",
       "      <td>290.42208</td>\n",
       "      <td>66.98577</td>\n",
       "      <td>-0.61199</td>\n",
       "      <td>2.053719e+07</td>\n",
       "      <td>1.602714e+07</td>\n",
       "      <td>-4.383432e+06</td>\n",
       "      <td>2.065940e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.429365e+09</td>\n",
       "      <td>G10</td>\n",
       "      <td>10</td>\n",
       "      <td>2.069873e+07</td>\n",
       "      <td>849.49657</td>\n",
       "      <td>48.68555</td>\n",
       "      <td>76.04460</td>\n",
       "      <td>65.66533</td>\n",
       "      <td>0.83612</td>\n",
       "      <td>2.088786e+07</td>\n",
       "      <td>1.343987e+07</td>\n",
       "      <td>1.129458e+07</td>\n",
       "      <td>2.027075e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.429365e+09</td>\n",
       "      <td>G23</td>\n",
       "      <td>23</td>\n",
       "      <td>2.277589e+07</td>\n",
       "      <td>3131.67460</td>\n",
       "      <td>39.14048</td>\n",
       "      <td>47.37784</td>\n",
       "      <td>25.36873</td>\n",
       "      <td>-4.55863</td>\n",
       "      <td>2.322375e+07</td>\n",
       "      <td>-2.775320e+06</td>\n",
       "      <td>1.519344e+07</td>\n",
       "      <td>2.162021e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gps_time satellite_id  sv_id   pseudorange  doppler_shift       cn0  \\\n",
       "0  1.429365e+09          G01      1  2.371945e+07    -3039.00801  42.97546   \n",
       "1  1.429365e+09          G02      2  2.160127e+07    -1837.17348  45.60996   \n",
       "2  1.429365e+09          G08      8  2.007511e+07     -926.01404  48.38570   \n",
       "3  1.429365e+09          G10     10  2.069873e+07      849.49657  48.68555   \n",
       "4  1.429365e+09          G23     23  2.277589e+07     3131.67460  39.14048   \n",
       "\n",
       "     azimuth  elevation  pseudorange_residual  pseudorange_corrected_cb  \\\n",
       "0  262.63392   15.78166              -0.46956              2.409778e+07   \n",
       "1  277.05302   44.45788               0.04192              2.185358e+07   \n",
       "2  290.42208   66.98577              -0.61199              2.053719e+07   \n",
       "3   76.04460   65.66533               0.83612              2.088786e+07   \n",
       "4   47.37784   25.36873              -4.55863              2.322375e+07   \n",
       "\n",
       "         sat_px        sat_py        sat_pz  sat_type  predicted_multipath  \\\n",
       "0  1.527411e+07 -2.033628e+07  7.613143e+06         0                  NaN   \n",
       "1  1.592333e+07 -1.252732e+07  1.739108e+07         0                  0.0   \n",
       "2  1.602714e+07 -4.383432e+06  2.065940e+07         0                  NaN   \n",
       "3  1.343987e+07  1.129458e+07  2.027075e+07         0                  NaN   \n",
       "4 -2.775320e+06  1.519344e+07  2.162021e+07         0                  1.0   \n",
       "\n",
       "   svm_decision_score  \n",
       "0                 NaN  \n",
       "1           -0.413365  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4            0.400355  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir_path = os.getcwd()\n",
    "#lstm_pred_data ='learning/real_with_predicted_multipath_LSTM.csv'# this is the result from lstm model\n",
    "real_world_data ='RWD_20250422/D1T4/observation_data_case5.csv'\n",
    "svm_pred_data ='learning/real_with_predicted_multipath_svm_bal.csv'\n",
    "uad_svm_pred_data ='RWD_20250422/D1T4/tgt_data_with_single_svm_predictions.csv'\n",
    "reference_truth_data ='RWD_20250422/D1T4/user_pos_full.csv'\n",
    "yuanlai_data ='RWD_20250422/D1T4/UAD_SVM_observation_data_case5_WITH_PREDICTIONS.csv'\n",
    "#lstm_pred = pd.read_csv(os.path.join(dir_path, lstm_pred_data))\n",
    "#svm_pred = pd.read_csv(os.path.join(dir_path, svm_pred_data))\n",
    "yuanlai = pd.read_csv(os.path.join(dir_path, yuanlai_data))\n",
    "real_world = pd.read_csv(os.path.join(dir_path, real_world_data))\n",
    "uad_svm_pred = pd.read_csv(os.path.join(dir_path, uad_svm_pred_data))\n",
    "svm_pred = pd.read_csv(os.path.join(dir_path, svm_pred_data))\n",
    "reference_truth_data = pd.read_csv(os.path.join(dir_path, reference_truth_data))\n",
    "#print(f\"正在从 '{lstm_pred_data}' 加载观测数据...\")\n",
    "#print(f\"正在从 '{svm_pred_data}' 加载观测数据...\")\n",
    "print(f\"正在从 '{uad_svm_pred_data}' 加载观测数据...\")\n",
    "#print(f\"正在从 '{yuanlai_data}' 加载观测数据...\")\n",
    "#display(lstm_pred.head())\n",
    "#display(svm_pred.head())\n",
    "display(uad_svm_pred.head())\n",
    "\n",
    "\n",
    "\n",
    "#真实地面值的坐标转换计算\n",
    "ecef_coords = reference_truth_data[['x', 'y', 'z']].values\n",
    "llh_coords = ecef_to_llh(ecef_coords)\n",
    "reference_truth_data['lat'] = llh_coords[:, 0]\n",
    "reference_truth_data['lon'] = llh_coords[:, 1]\n",
    "reference_truth_data['h'] = llh_coords[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "756b7798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 Soft-WLS 权重计算函数\n",
    "def get_soft_weights(scores, k=1.0):\n",
    "    \n",
    "    # 限制范围防止 exp 溢出 (虽然 np.exp 处理 float64 范围很大，但加个保险更好)\n",
    "    safe_scores = np.clip(k * scores, -100, 100)\n",
    "    \n",
    "    # 计算权重\n",
    "    # Score < 0 (好信号) -> exp 趋近 0 -> 权重 趋近 1\n",
    "    # Score > 0 (坏信号) -> exp 很大   -> 权重 趋近 0\n",
    "    weights = 1.0 / (1.0 + np.exp(safe_scores))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed3679aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理每个时间点的数据...\n",
      "gps_time\n",
      "1.429365e+09     5\n",
      "1.429365e+09     5\n",
      "1.429365e+09     5\n",
      "1.429365e+09     5\n",
      "1.429365e+09     5\n",
      "                ..\n",
      "1.429365e+09    17\n",
      "1.429365e+09    13\n",
      "1.429365e+09    17\n",
      "1.429365e+09    17\n",
      "1.429365e+09    17\n",
      "Length: 832, dtype: int64\n",
      "总共有 832 个独立的时间点。\n"
     ]
    }
   ],
   "source": [
    "grouped_data = uad_svm_pred.groupby('gps_time')\n",
    "#grouped_data = yuanlai.groupby('gps_time')\n",
    "#num_unique_times = svm_pred['gps_time'].nunique()\n",
    "#num_unique_times_real_world= real_world['gps_time'].nunique()\n",
    "#print(f\"真实观测数据总共有: {num_unique_times_real_world} 个不同的（不重复的）时间点。\")\n",
    "#num_unique_times_yuanlai= yuanlai['gps_time'].nunique()\n",
    "#print(f\" 总共有: {num_unique_times_yuanlai} 个不同的（不重复的）时间点。\")\n",
    "\n",
    "results_spp = {}        # 情况1: 标准SPP \n",
    "results_wls = {}        # 情况2: 加权SPP (WLS)\n",
    "results_exclusion = {}  # 情况3: 剔除坏信号后的SPP \n",
    "\n",
    "\n",
    "#skip_count_sat = 0   # 卫星数不足跳过\n",
    "skip_count_unit = 0  # 单位错误跳过\n",
    "sat_count_stats = []\n",
    "print(\"开始处理每个时间点的数据...\")\n",
    "print(grouped_data.size())\n",
    "print(f\"总共有 {len(grouped_data)} 个独立的时间点。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53a13161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有数据处理完毕\n",
      "标准SPP: 828 个点\n",
      "加权WLS: 828 个点\n",
      "剔除坏信号SPP: 794 个点\n"
     ]
    }
   ],
   "source": [
    "for timestamp, group in grouped_data:\n",
    "    valid_group = group[(group['sat_type']!= -1) & (group['svm_decision_score'].notna())].copy()\n",
    "    # ------------------ [修正 1] ------------------\n",
    "    # 解算 (X,Y,Z, dt_gps, isb_pl) 至少需要 4 颗卫星\n",
    "    if len(group) < 4: \n",
    "        continue\n",
    "    \n",
    "    all_sat_positions = valid_group[['sat_px', 'sat_py', 'sat_pz']].values\n",
    "    all_pseudoranges = valid_group['pseudorange_corrected_cb'].values\n",
    "    \n",
    "    # # ------------------ [修正 2] ------------------\n",
    "    # # 必须提取 sat_type 以区分 GPS / PL\n",
    "    # all_sat_types = group['sat_type'].values \n",
    "    unified_sat_types = np.zeros(len(valid_group))#这个需要统一一下 因为后面函数需要区分，并且有提到 gnss和pl在数据处理过程中已经消除了 钟差\n",
    "    # ----------------------------------------------\n",
    "\n",
    "    # --- 情况一：标准SPP ---\n",
    "    try:\n",
    "        spp_pos, _, _ = multi_constellation_spp(all_sat_positions, all_pseudoranges, unified_sat_types)\n",
    "        results_spp[timestamp] = spp_pos\n",
    "    except Exception as e:\n",
    "        pass # 解算失败，跳过\n",
    "\n",
    "    # --- 情况二：加权SPP (WLS) (您的SVM模型应用在这里) ---\n",
    "    \n",
    "    try:\n",
    "        scores = valid_group['svm_decision_score'].values\n",
    "        w = get_soft_weights(scores, k=3.0)\n",
    "\n",
    "        #weights = group['predicted_multipath'].apply(lambda x: 0.1 if x == 1 else 1.0).values\n",
    "        wls_pos, _, _ = weighted_multi_constellation_spp(all_sat_positions, all_pseudoranges, unified_sat_types, w)\n",
    "        results_wls[timestamp] = wls_pos\n",
    "    except Exception as e:\n",
    "        pass # 解算失败，跳过\n",
    "\n",
    "    \n",
    "    # --- 情况三：剔除坏信号 SPP (Exclusion) ---\n",
    "    # 1. 生成掩码\n",
    "    good_mask = valid_group['predicted_multipath'] == 0\n",
    "    \n",
    "    # 2. 检查数量\n",
    "    if good_mask.sum() >= 4:\n",
    "        try:\n",
    "            # 3. 数据切片 (使用上面定义好的变量，不要重新从 DF 读)\n",
    "            # 【修正】这里一定要用 all_sat_positions 和 all_pseudoranges\n",
    "            g_pos = all_sat_positions[good_mask]\n",
    "            g_pr = all_pseudoranges[good_mask]\n",
    "            g_types = unified_sat_types[good_mask] # 全0\n",
    "            \n",
    "            # 4. 解算\n",
    "            exclusion_pos, _, _ = multi_constellation_spp(g_pos, g_pr, g_types)\n",
    "            if exclusion_pos is not None:\n",
    "                # 计算地心距离\n",
    "                r = np.linalg.norm(exclusion_pos)\n",
    "                \n",
    "                # 只有结果在地球表面 (6000km~7000km) 才保留\n",
    "                # 那些算出 10万公里的点，在这里会被拦截，相当于以前的\"崩溃\"\n",
    "                if 6000000 < r < 7000000:\n",
    "                    results_exclusion[timestamp] = exclusion_pos\n",
    "                else:\n",
    "                    # 这是一个\"飞点\" (几何构型太差)\n",
    "                    # 我们选择 pass，就像之前 try...except 捕获了错误一样\n",
    "                    pass\n",
    "            \n",
    "            #results_exclusion[timestamp] = exclusion_pos\n",
    "            \n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "# if skip_count_unit > 0:\n",
    "#     print(f\"⚠️ 跳过了 {skip_count_unit} 个疑似残差数据的历元。\")  print(\"所有数据处理完毕\")\n",
    "if skip_count_unit > 0:\n",
    "    print(f\"⚠️ 警告: 跳过了 {skip_count_unit} 个包含负数数据的历元。\")          \n",
    "print(\"所有数据处理完毕\")\n",
    "print(f\"标准SPP: {len(results_spp)} 个点\")\n",
    "print(f\"加权WLS: {len(results_wls)} 个点\")\n",
    "print(f\"剔除坏信号SPP: {len(results_exclusion)} 个点\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2721236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. SPP 的ECEF坐标已转换为ENU坐标，包含 828 个点。\n",
      "2. WLS  的ECEF坐标已转换为ENU坐标，包含 828 个点。\n",
      "3. Exclusion SPP 的ECEF坐标已转换为ENU坐标，包含 794 个点。\n",
      "所有场景的ECEF坐标已成功转换为ENU坐标。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 定义ENU坐标系的原点 (使用参考轨迹的第一个点)\n",
    "origin_llh = reference_truth_data[['lat', 'lon', 'h']].iloc[0].values\n",
    "\n",
    "# 将参考轨迹也转换为ENU以进行对比\n",
    "reference_llh = reference_truth_data[['lat', 'lon', 'h']].values\n",
    "reference_enu = llh_to_enu(reference_llh, origin_llh)\n",
    "\n",
    "# 存储所有ECEF结果，方便循环处理\n",
    "all_results_ecef = {\n",
    "    '1. SPP': results_spp,\n",
    "    '2. WLS ': results_wls,\n",
    "    '3. Exclusion SPP': results_exclusion\n",
    "}\n",
    "\n",
    "all_results_enu = {}\n",
    "for name, ecef_results in all_results_ecef.items():\n",
    "    if ecef_results:\n",
    "        ecef_points = np.array(list(ecef_results.values()))\n",
    "        llh_points = ecef_to_llh(ecef_points)\n",
    "        enu_trajectory = llh_to_enu(llh_points, origin_llh)\n",
    "        all_results_enu[name] = enu_trajectory\n",
    "        print(f\"{name} 的ECEF坐标已转换为ENU坐标，包含 {len(enu_trajectory)} 个点。\")\n",
    "print(\"所有场景的ECEF坐标已成功转换为ENU坐标。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "584b6cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%matplotlib qt\n",
    "# 准备最终的绘图数据字典\n",
    "plot_data = {\n",
    "    \"Ground Truth\": reference_enu,#来自user_pos_full.csv的参考轨迹\n",
    "    **all_results_enu  # 使用字典解包，将所有计算出的轨迹加入\n",
    "}\n",
    "\n",
    "# 调用您自己编写的绘图函数，并设置 scatter=True\n",
    "fig = plot_trajectory(\n",
    "    plot_data,\n",
    "    title=\" (ENU coordinate)\",\n",
    "    type=\"enu\",\n",
    "    twoD=True,\n",
    "    scatter=True \n",
    ")\n",
    "\n",
    "# 添加更多绘图细节，让图像更清晰\n",
    "plt.xlabel(\"East (m)\")\n",
    "plt.ylabel(\"North (m)\")\n",
    "plt.grid(True)\n",
    "plt.axis('equal') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "85946a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# 准备最终的绘图数据字典\n",
    "plot_data = {\n",
    "    \"(Ground Truth)\": reference_enu,\n",
    "    **all_results_enu\n",
    "}\n",
    "\n",
    "# 调用您自己编写的绘图函数\n",
    "\n",
    "fig = plot_trajectory(\n",
    "    plot_data,\n",
    "    title=\"(ENU coordinate)\",\n",
    "    type=\"enu\",\n",
    "    twoD=True,\n",
    "    scatter=False\n",
    ")\n",
    "\n",
    "# 您可以在此基础上添加更多绘图细节\n",
    "plt.xlabel(\"East (m)\")\n",
    "plt.ylabel(\"North (m)\")\n",
    "# plt.axis('equal') # 保持XY轴比例一致，如果轨迹范围太大可能导致图像被压缩\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2bebb514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "真实轨迹: 1111 点, 估计结果: 828 点\n",
      "成功匹配的点数: 828\n",
      "\n",
      "=== 剔除坏信号 (Good Signals Only) 性能评估 ===\n",
      "样本数: 828 / 匹配成功率: 100.0%\n",
      "Mean 误差 (E, N, U) [m]: [ 2.56484404 -3.53531255 -1.83658534]\n",
      "RMSE 误差 (E, N, U) [m]: [13.02505687 33.23427808 18.20198211]\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ 准备真值 (ref_df)\n",
    "ref_df = reference_truth_data[['gps_time', 'x', 'y', 'z']].copy()\n",
    "# 必须将 gps_time 保持为 float (浮点数) 类型\n",
    "ref_df['gps_time'] = ref_df['gps_time'].astype(float) \n",
    "ref_df = ref_df.sort_values('gps_time').reset_index(drop=True)\n",
    "\n",
    "# 2️⃣ 准备估计结果 (est_df) - 以 \"加权WLS\" (情况2) 为例\n",
    "# (您应该为您关心的那组结果计算误差)\n",
    "est_df = pd.DataFrame([\n",
    "    [t, pos[0], pos[1], pos[2]] for t, pos in results_wls.items()\n",
    "], columns=['gps_time', 'x_est', 'y_est', 'z_est'])\n",
    "\n",
    "# 确保 est_df 的时间也是 float\n",
    "if not est_df.empty:\n",
    "    est_df['gps_time'] = est_df['gps_time'].astype(float)\n",
    "    est_df = est_df.sort_values('gps_time').reset_index(drop=True)\n",
    "else:\n",
    "    print(\"错误：估计结果 (est_df) 为空，无法计算误差。\")\n",
    "    # 在这里可以停止或跳过\n",
    "\n",
    "print(f\"真实轨迹: {len(ref_df)} 点, 估计结果: {len(est_df)} 点\")\n",
    "\n",
    "# 3️⃣ 使用 pandas.merge_asof 按时间对齐\n",
    "# 两个DataFrame的 'gps_time' 都是 float 了，\n",
    "# 'tolerance=0.5' (float) 才能正常工作\n",
    "aligned = pd.merge_asof(\n",
    "    est_df, ref_df,\n",
    "    on='gps_time',\n",
    "    direction='nearest', # 寻找最近的时间戳\n",
    "    tolerance=0.5      # 允许的最大时差 (0.5秒)\n",
    ").dropna()\n",
    "\n",
    "print(f\"成功匹配的点数: {len(aligned)}\")\n",
    "\n",
    "# 4️⃣ 坐标转换：ECEF → ENU\n",
    "if not aligned.empty:\n",
    "    origin_llh = ecef_to_llh(ref_df[['x', 'y', 'z']].values[:1])[0]\n",
    "    ref_llh = ecef_to_llh(aligned[['x', 'y', 'z']].values)\n",
    "    est_llh = ecef_to_llh(aligned[['x_est', 'y_est', 'z_est']].values)\n",
    "    \n",
    "    ref_enu = llh_to_enu(ref_llh, origin_llh)\n",
    "    est_enu = llh_to_enu(est_llh, origin_llh)\n",
    "\n",
    "# 5️⃣ 计算误差\n",
    "errors = est_enu - ref_enu\n",
    "mean_error = np.mean(errors, axis=0)\n",
    "rmse = np.sqrt(np.mean(errors**2, axis=0))\n",
    "rmse_2d = np.sqrt(rmse[0]**2 + rmse[1]**2)\n",
    "rmse_3d = np.sqrt(np.sum(rmse**2))\n",
    "\n",
    "# 6️⃣ 打印结果\n",
    "print(\"\\n=== 剔除坏信号 (Good Signals Only) 性能评估 ===\")\n",
    "print(f\"样本数: {len(aligned)} / 匹配成功率: {len(aligned)/len(est_df)*100:.1f}%\")\n",
    "print(f\"Mean 误差 (E, N, U) [m]: {mean_error}\")\n",
    "print(f\"RMSE 误差 (E, N, U) [m]: {rmse}\")\n",
    "#print(f\"2D RMSE: {rmse_2d:.3f} m | 3D RMSE: {rmse_3d:.3f} m\")\n",
    "\n",
    "# 7️⃣ 可视化误差随时间\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(errors[:,0], label='East Error')\n",
    "plt.plot(errors[:,1], label='North Error')\n",
    "plt.plot(errors[:,2], label='Up Error')\n",
    "plt.xlabel('Epoch Index')\n",
    "plt.ylabel('Error (m)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('ENU Error over Time (Good Signal SPP)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a98c2eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================================================================\n",
      "Method               | Count  | 2D RMSE    | 3D RMSE    | East     | North    | Up      \n",
      "-----------------------------------------------------------------------------------------------\n",
      "1. Standard SPP      | 804    | 38.251     | 43.020     | 13.540   | 35.774   | 19.687  \n",
      "2. Weighted SPP      | 804    | 36.097     | 40.529     | 13.124   | 33.627   | 18.427  \n",
      "3. Exclusion SPP     | 770    | 29.193     | 35.830     | 11.475   | 26.844   | 20.773  \n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 误差计算与对比表格 (Format Output)\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*95)\n",
    "print(f\"{'Method':<20} | {'Count':<6} | {'2D RMSE':<10} | {'3D RMSE':<10} | {'East':<8} | {'North':<8} | {'Up':<8}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "# 准备真值 (排序加速匹配)\n",
    "gt_df = reference_truth_data[['gps_time', 'x', 'y', 'z']].sort_values('gps_time')\n",
    "# 确保真值时间也是 float\n",
    "gt_df['gps_time'] = gt_df['gps_time'].astype(float)\n",
    "\n",
    "# 把三个结果字典放进一个列表，方便循环\n",
    "methods = [\n",
    "    ('1. Standard SPP', results_spp),\n",
    "    ('2. Weighted SPP', results_wls),\n",
    "    ('3. Exclusion SPP', results_exclusion)\n",
    "]\n",
    "\n",
    "for name, res_dict in methods:\n",
    "    if not res_dict:\n",
    "        print(f\"{name:<20} | {'No Data':<6}\")\n",
    "        continue\n",
    "        \n",
    "    # 1. 字典转 DataFrame\n",
    "    est_df = pd.DataFrame.from_dict(res_dict, orient='index', columns=['x_est', 'y_est', 'z_est'])\n",
    "    est_df.index.name = 'gps_time'\n",
    "    est_df = est_df.reset_index().sort_values('gps_time')\n",
    "    est_df['gps_time'] = est_df['gps_time'].astype(float)\n",
    "    \n",
    "    # 2. 与真值对齐 (Tolerance 0.1s)\n",
    "    merged = pd.merge_asof(est_df, gt_df, on='gps_time', direction='nearest', tolerance=0.1).dropna()\n",
    "    \n",
    "    if merged.empty:\n",
    "        print(f\"{name:<20} | {'Unmatched':<6}\")\n",
    "        continue\n",
    "        \n",
    "    # 3. 坐标转换 (ECEF -> ENU)\n",
    "    # origin_llh 在前面你已经定义过了\n",
    "    est_llh = ecef_to_llh(merged[['x_est', 'y_est', 'z_est']].values)\n",
    "    gt_llh = ecef_to_llh(merged[['x', 'y', 'z']].values)\n",
    "    \n",
    "    est_enu = llh_to_enu(est_llh, origin_llh)\n",
    "    gt_enu = llh_to_enu(gt_llh, origin_llh)\n",
    "    \n",
    "    # 4. 计算误差\n",
    "    diff = est_enu - gt_enu\n",
    "    \n",
    "    # 分量 RMSE\n",
    "    rmse_e = np.sqrt(np.mean(diff[:, 0]**2))\n",
    "    rmse_n = np.sqrt(np.mean(diff[:, 1]**2))\n",
    "    rmse_u = np.sqrt(np.mean(diff[:, 2]**2))\n",
    "    \n",
    "    # 综合 RMSE\n",
    "    rmse_2d = np.sqrt(rmse_e**2 + rmse_n**2)\n",
    "    rmse_3d = np.sqrt(rmse_e**2 + rmse_n**2 + rmse_u**2)\n",
    "    \n",
    "    # 5. 打印一行漂亮的结果\n",
    "    print(f\"{name:<20} | {len(merged):<6} | {rmse_2d:<10.3f} | {rmse_3d:<10.3f} | {rmse_e:<8.3f} | {rmse_n:<8.3f} | {rmse_u:<8.3f}\")\n",
    "\n",
    "print(\"=\"*95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
