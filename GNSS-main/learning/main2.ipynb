{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c3f270-b521-4889-b0b7-647ff14a42c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12614\n",
      "5788\n",
      "\n",
      "ğŸ“¦ Case 0: observation_data_case5.csv\n",
      "  â–¶ Length     : 12614 rows\n",
      "  â–¶ Duration   : 52.50 s\n",
      "  â–¶ Columns    : 13 â†’ ['gps_time', 'satellite_id', 'sv_id', 'pseudorange', 'doppler_shift', 'cn0', 'azimuth', 'elevation', 'pseudorange_residual', 'pseudorange_corrected_cb', 'sat_px', 'sat_py', 'sat_pz']\n",
      "  â–¶ PL         : 1394 (LOS: 0, NLOS: 0) (LOS %: 0.0%, NLOS %: 0.0%)\n",
      "  â–¶ GPS        : 5788 (LOS: 0, NLOS: 0) (LOS %: 0.0%, NLOS %: 0.0%)\n",
      "91719\n",
      "55773\n",
      "\n",
      "ğŸ“¦ Case 1: Case1_Urban_10Hz.csv\n",
      "  â–¶ Length     : 91719 rows\n",
      "  â–¶ Duration   : 599.00 s\n",
      "  â–¶ Columns    : 12 â†’ ['gps_time', 'satellite_id', 'sv_id', 'pseudorange', 'doppler_shift', 'cn0', 'rec_pow', 'azimuth', 'elevation', 'pseudorange_residual', 'pseudorange_corrected_cb', 'multipath']\n",
      "  â–¶ PL         : 35946 (LOS: 29912, NLOS: 6034) (LOS %: 83.2%, NLOS %: 16.8%)\n",
      "  â–¶ GPS        : 55773 (LOS: 10853, NLOS: 44920) (LOS %: 19.5%, NLOS %: 80.5%)\n",
      "  â–¶ Total SIG  : LOS: 40765, NLOS: 50954 (LOS %: 44.4%, NLOS %: 55.6%)\n",
      "91719\n",
      "55773\n",
      "\n",
      "ğŸ“¦ Case 2: Case1_Suburban_10Hz.csv\n",
      "  â–¶ Length     : 91719 rows\n",
      "  â–¶ Duration   : 599.00 s\n",
      "  â–¶ Columns    : 12 â†’ ['gps_time', 'satellite_id', 'sv_id', 'pseudorange', 'doppler_shift', 'cn0', 'rec_pow', 'azimuth', 'elevation', 'pseudorange_residual', 'pseudorange_corrected_cb', 'multipath']\n",
      "  â–¶ PL         : 35946 (LOS: 26860, NLOS: 9086) (LOS %: 74.7%, NLOS %: 25.3%)\n",
      "  â–¶ GPS        : 55773 (LOS: 18623, NLOS: 37150) (LOS %: 33.4%, NLOS %: 66.6%)\n",
      "  â–¶ Total SIG  : LOS: 45483, NLOS: 46236 (LOS %: 49.6%, NLOS %: 50.4%)\n",
      "79856\n",
      "55773\n",
      "\n",
      "ğŸ“¦ Case 3: Case2_Urban_10Hz.csv\n",
      "  â–¶ Length     : 79856 rows\n",
      "  â–¶ Duration   : 599.00 s\n",
      "  â–¶ Columns    : 12 â†’ ['gps_time', 'satellite_id', 'sv_id', 'pseudorange', 'doppler_shift', 'cn0', 'rec_pow', 'azimuth', 'elevation', 'pseudorange_residual', 'pseudorange_corrected_cb', 'multipath']\n",
      "  â–¶ PL         : 24083 (LOS: 19719, NLOS: 4364) (LOS %: 81.9%, NLOS %: 18.1%)\n",
      "  â–¶ GPS        : 55773 (LOS: 9894, NLOS: 45879) (LOS %: 17.7%, NLOS %: 82.3%)\n",
      "  â–¶ Total SIG  : LOS: 29613, NLOS: 50243 (LOS %: 37.1%, NLOS %: 62.9%)\n",
      "79894\n",
      "55772\n",
      "\n",
      "ğŸ“¦ Case 4: Case2_Suburban_10Hz.csv\n",
      "  â–¶ Length     : 79894 rows\n",
      "  â–¶ Duration   : 599.90 s\n",
      "  â–¶ Columns    : 12 â†’ ['gps_time', 'satellite_id', 'sv_id', 'pseudorange', 'doppler_shift', 'cn0', 'rec_pow', 'azimuth', 'elevation', 'pseudorange_residual', 'pseudorange_corrected_cb', 'multipath']\n",
      "  â–¶ PL         : 24122 (LOS: 19978, NLOS: 4144) (LOS %: 82.8%, NLOS %: 17.2%)\n",
      "  â–¶ GPS        : 55772 (LOS: 15249, NLOS: 40523) (LOS %: 27.3%, NLOS %: 72.7%)\n",
      "  â–¶ Total SIG  : LOS: 35227, NLOS: 44667 (LOS %: 44.1%, NLOS %: 55.9%)\n",
      "91718\n",
      "55772\n",
      "\n",
      "ğŸ“¦ Case 5: Case3_Urban_10Hz.csv\n",
      "  â–¶ Length     : 91718 rows\n",
      "  â–¶ Duration   : 599.00 s\n",
      "  â–¶ Columns    : 12 â†’ ['gps_time', 'satellite_id', 'sv_id', 'pseudorange', 'doppler_shift', 'cn0', 'rec_pow', 'azimuth', 'elevation', 'pseudorange_residual', 'pseudorange_corrected_cb', 'multipath']\n",
      "  â–¶ PL         : 35946 (LOS: 33563, NLOS: 2383) (LOS %: 93.4%, NLOS %: 6.6%)\n",
      "  â–¶ GPS        : 55772 (LOS: 13029, NLOS: 42743) (LOS %: 23.4%, NLOS %: 76.6%)\n",
      "  â–¶ Total SIG  : LOS: 46592, NLOS: 45126 (LOS %: 50.8%, NLOS %: 49.2%)\n",
      "91719\n",
      "55773\n",
      "\n",
      "ğŸ“¦ Case 6: Case3_Suburban_10Hz.csv\n",
      "  â–¶ Length     : 91719 rows\n",
      "  â–¶ Duration   : 599.00 s\n",
      "  â–¶ Columns    : 12 â†’ ['gps_time', 'satellite_id', 'sv_id', 'pseudorange', 'doppler_shift', 'cn0', 'rec_pow', 'azimuth', 'elevation', 'pseudorange_residual', 'pseudorange_corrected_cb', 'multipath']\n",
      "  â–¶ PL         : 35946 (LOS: 33418, NLOS: 2528) (LOS %: 93.0%, NLOS %: 7.0%)\n",
      "  â–¶ GPS        : 55773 (LOS: 12768, NLOS: 43005) (LOS %: 22.9%, NLOS %: 77.1%)\n",
      "  â–¶ Total SIG  : LOS: 46186, NLOS: 45533 (LOS %: 50.4%, NLOS %: 49.6%)\n",
      "91719\n",
      "55773\n",
      "\n",
      "ğŸ“¦ Case 7: Case4_Urban_10Hz.csv\n",
      "  â–¶ Length     : 91719 rows\n",
      "  â–¶ Duration   : 599.00 s\n",
      "  â–¶ Columns    : 12 â†’ ['gps_time', 'satellite_id', 'sv_id', 'pseudorange', 'doppler_shift', 'cn0', 'rec_pow', 'azimuth', 'elevation', 'pseudorange_residual', 'pseudorange_corrected_cb', 'multipath']\n",
      "  â–¶ PL         : 35946 (LOS: 33310, NLOS: 2636) (LOS %: 92.7%, NLOS %: 7.3%)\n",
      "  â–¶ GPS        : 55773 (LOS: 10011, NLOS: 45762) (LOS %: 17.9%, NLOS %: 82.1%)\n",
      "  â–¶ Total SIG  : LOS: 43321, NLOS: 48398 (LOS %: 47.2%, NLOS %: 52.8%)\n",
      "91719\n",
      "55773\n",
      "\n",
      "ğŸ“¦ Case 8: Case4_Suburban_10Hz.csv\n",
      "  â–¶ Length     : 91719 rows\n",
      "  â–¶ Duration   : 599.00 s\n",
      "  â–¶ Columns    : 12 â†’ ['gps_time', 'satellite_id', 'sv_id', 'pseudorange', 'doppler_shift', 'cn0', 'rec_pow', 'azimuth', 'elevation', 'pseudorange_residual', 'pseudorange_corrected_cb', 'multipath']\n",
      "  â–¶ PL         : 35946 (LOS: 33802, NLOS: 2144) (LOS %: 94.0%, NLOS %: 6.0%)\n",
      "  â–¶ GPS        : 55773 (LOS: 12445, NLOS: 43328) (LOS %: 22.3%, NLOS %: 77.7%)\n",
      "  â–¶ Total SIG  : LOS: 46247, NLOS: 45472 (LOS %: 50.4%, NLOS %: 49.6%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "\n",
    "base_dir = os.getcwd()  \n",
    "parent_dir = os.path.dirname(base_dir)    \n",
    "csv_path = {0: os.path.join(parent_dir, \"RWD_20250422/D1T4\", \"observation_data_case5.csv\"),\n",
    "            1: os.path.join(parent_dir, \"for_real\", \"Case1_Urban_10Hz.csv\"),\n",
    "            2: os.path.join(parent_dir, \"for_real\", \"Case1_Suburban_10Hz.csv\"),\n",
    "            3: os.path.join(parent_dir, \"for_real\", \"Case2_Urban_10Hz.csv\"),\n",
    "            4: os.path.join(parent_dir, \"for_real\", \"Case2_Suburban_10Hz.csv\"),\n",
    "            5: os.path.join(parent_dir, \"for_real\", \"Case3_Urban_10Hz.csv\"),\n",
    "            6: os.path.join(parent_dir, \"for_real\", \"Case3_Suburban_10Hz.csv\"),\n",
    "            7: os.path.join(parent_dir, \"for_real\", \"Case4_Urban_10Hz.csv\"),\n",
    "            8: os.path.join(parent_dir, \"for_real\", \"Case4_Suburban_10Hz.csv\"),\n",
    "            }\n",
    "\n",
    "\n",
    "data = {}\n",
    "for key in csv_path.keys():\n",
    "    # data[key] = pd.read_csv(csv_path[key])\n",
    "    # print('\\n Case', key, ': Length of data =', len(data[key]['gps_time']), ', Duration =', data[key]['gps_time'].iloc[-1] - data[key]['gps_time'].iloc[0], 's, columns =', data[key].columns.tolist())\n",
    "    # print(data[key].head())\n",
    "    \n",
    "    df = pd.read_csv(csv_path[key])\n",
    "    length = len(df)\n",
    "    print(length)\n",
    "    duration = df['gps_time'].iloc[-1] - df['gps_time'].iloc[0] if length > 1 else 0\n",
    "    columns = df.columns.tolist()\n",
    "    # Type masks\n",
    "    pl_mask = df['satellite_id'].str.startswith(\"P\")\n",
    "    pl_total = pl_mask.sum()\n",
    "    gps_mask = df['satellite_id'].str.startswith(\"G\")\n",
    "    gps_total = gps_mask.sum()\n",
    "    print(gps_total)\n",
    "    # Multipath labels\n",
    "    if key == 0:\n",
    "        total_los = total_nlos = pl_los = pl_nlos = gps_los = gps_nlos = 0\n",
    "    else:\n",
    "        total_los  = (df['multipath'] == 0).sum()\n",
    "        total_nlos = (df['multipath'] == 1).sum()\n",
    "        \n",
    "        pl_los  = ((pl_mask) & (df['multipath'] == 0)).sum()\n",
    "        pl_nlos = ((pl_mask) & (df['multipath'] == 1)).sum()\n",
    "\n",
    "        gps_los  = ((gps_mask) & (df['multipath'] == 0)).sum()\n",
    "        gps_nlos = ((gps_mask) & (df['multipath'] == 1)).sum()\n",
    "\n",
    "    # Print formatted summary\n",
    "    print(f\"\\nğŸ“¦ Case {key}: {os.path.basename(csv_path[key])}\")\n",
    "    print(f\"  â–¶ Length     : {length} rows\")\n",
    "    print(f\"  â–¶ Duration   : {duration:.2f} s\")\n",
    "    print(f\"  â–¶ Columns    : {len(columns)} â†’ {columns}\")\n",
    "    print(f\"  â–¶ PL         : {pl_total} (LOS: {pl_los}, NLOS: {pl_nlos}) (LOS %: {pl_los/pl_total*100:.1f}%, NLOS %: {pl_nlos/pl_total*100:.1f}%)\")\n",
    "    print(f\"  â–¶ GPS        : {gps_total} (LOS: {gps_los}, NLOS: {gps_nlos}) (LOS %: {gps_los/gps_total*100:.1f}%, NLOS %: {gps_nlos/gps_total*100:.1f}%)\")\n",
    "    if key != 0:\n",
    "        print(f\"  â–¶ Total SIG  : LOS: {total_los}, NLOS: {total_nlos} (LOS %: {total_los/(total_los+total_nlos)*100:.1f}%, NLOS %: {total_nlos/(total_los+total_nlos)*100:.1f}%)\")\n",
    "\n",
    "#è¿™ä¸ª é‡Œé¢æ˜¯æŠŠæ‰€æœ‰çš„æ•°æ®æ–‡ä»¶ä¸­çš„å…¨ä½“ä¿¡å·æ•°é‡å æ¯”æ‰“å°å‡ºæ¥ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a94f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any real data OTHER than PL/GPS? True\n",
      "Any train data OTHER than PL/GPS? False\n",
      "Any test data OTHER than PL/GPS? False\n"
     ]
    }
   ],
   "source": [
    "# Define cases\n",
    "real_case = 0\n",
    "# training_data = [1,2,3,4,5,6]\n",
    "# testing_data = [7,8]\n",
    "training_data = [2,3]\n",
    "testing_data = [4]\n",
    "\n",
    "\n",
    "# Load real case\n",
    "df_real = pd.read_csv(csv_path[real_case])\n",
    "\n",
    "# Load training cases into one DataFrame\n",
    "df_train = pd.concat(\n",
    "    [pd.read_csv(csv_path[k]).assign(case_id=k) for k in training_data],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Load testing cases into one DataFrame\n",
    "df_test = pd.concat(\n",
    "    [pd.read_csv(csv_path[k]).assign(case_id=k) for k in testing_data],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Classify satellite types in all DataFrames (PL=1, GPS=0, OTHER=-1)\n",
    "for df in [df_real, df_train, df_test]:\n",
    "    df['satellite_id'] = df['satellite_id'].astype(str)\n",
    "    df['sat_type'] = np.where(\n",
    "        df['satellite_id'].str.contains(\"^P\", na=False), 1, # ^ means â€œstart of stringâ€.\n",
    "        np.where(df['satellite_id'].str.contains(\"^G\", na=False), 0, -1)\n",
    "    )\n",
    "\n",
    "print(\"Any real data OTHER than PL/GPS?\", (df_real['sat_type'] == -1).any())\n",
    "print(\"Any train data OTHER than PL/GPS?\", (df_train['sat_type'] == -1).any())\n",
    "print(\"Any test data OTHER than PL/GPS?\", (df_test['sat_type'] == -1).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6100f6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Feature: doppler_shift\n",
      "  sat_type 0: Real mean = -191.2868, Train mean = -27.4664, Diff = -163.8204\n",
      "  sat_type 1: Real mean = 52.1876, Train mean = -0.0011, Diff = 52.1887\n",
      "\n",
      "ğŸ“Š Feature: elevation\n",
      "  sat_type 0: Real mean = 43.2567, Train mean = 35.3412, Diff = 7.9155\n",
      "  sat_type 1: Real mean = 4.4673, Train mean = 15.5046, Diff = -11.0373\n",
      "\n",
      "ğŸ“Š Feature: pseudorange_residual\n",
      "  sat_type 0: Real mean = -0.3730, Train mean = -0.3427, Diff = -0.0304\n",
      "  sat_type 1: Real mean = 1.2762, Train mean = -0.3049, Diff = 1.5811\n",
      "\n",
      "ğŸ“Š Feature: pseudorange_corrected_cb\n",
      "  sat_type 0: Real mean = 22186348.1537, Train mean = 22612315.6011, Diff = -425967.4474\n",
      "  sat_type 1: Real mean = 26.7248, Train mean = 22.5770, Diff = 4.1478\n",
      "\n",
      "ğŸ“Š Feature: cn0\n",
      "  sat_type 0: Real mean = 43.6147, Train mean = 36.2806, Diff = 7.3341\n",
      "  sat_type 1: Real mean = 47.7305, Train mean = 167.2583, Diff = -119.5279\n"
     ]
    }
   ],
   "source": [
    "for col in [\"doppler_shift\", \"elevation\", \"pseudorange_residual\", \"pseudorange_corrected_cb\", \"cn0\"]:\n",
    "    print(f\"\\nğŸ“Š Feature: {col}\")\n",
    "    for sat_type in [0, 1]:  # 0 = GPS, 1 = PL\n",
    "        real_mask = df_real[\"sat_type\"] == sat_type\n",
    "        train_mask = df_train[\"sat_type\"] == sat_type\n",
    "\n",
    "        real_mean = df_real.loc[real_mask, col].mean()\n",
    "        train_mean = df_train.loc[train_mask, col].mean()\n",
    "        diff = real_mean - train_mean\n",
    "\n",
    "        print(f\"  sat_type {sat_type}: Real mean = {real_mean:.4f}, Train mean = {train_mean:.4f}, Diff = {diff:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ec8950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real PL median: 48.8056396296138, Train PL median: 170.05416582270487, Diff: -121.24852619309107\n",
      "Real GPS median: 45.4344222328504, Train GPS median: 42.0615650724157, Diff: 3.372857160434698\n",
      "After adjustment, New Train PL median: 48.80563962961381\n",
      "After adjustment, New Train GPS median: 45.434422232850395\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Compute real-world medians for PL and GPS ---\n",
    "real_pl_med  = df_real.loc[df_real['sat_type'] == 1, 'cn0'].median()\n",
    "real_gps_med = df_real.loc[df_real['sat_type'] == 0, 'cn0'].median()\n",
    "\n",
    "# --- Align cn0 in training data ---\n",
    "train_pl_med  = df_train.loc[df_train['sat_type'] == 1, 'cn0'].median()\n",
    "train_gps_med = df_train.loc[df_train['sat_type'] == 0, 'cn0'].median()\n",
    "\n",
    "diff_pl  = real_pl_med  - train_pl_med\n",
    "diff_gps = real_gps_med - train_gps_med\n",
    "\n",
    "df_train['cn0_new'] = df_train['cn0']\n",
    "df_test['cn0_new'] = df_test['cn0']\n",
    "df_train.loc[df_train['sat_type'] == 1, 'cn0_new'] += diff_pl\n",
    "df_train.loc[df_train['sat_type'] == 0, 'cn0_new'] += diff_gps\n",
    "df_test.loc[df_test['sat_type'] == 1, 'cn0_new'] += diff_pl\n",
    "df_test.loc[df_test['sat_type'] == 0, 'cn0_new'] += diff_gps\n",
    "\n",
    "print(f\"Real PL median: {real_pl_med}, Train PL median: {train_pl_med}, Diff: {diff_pl}\")\n",
    "print(f\"Real GPS median: {real_gps_med}, Train GPS median: {train_gps_med}, Diff: {diff_gps}\")\n",
    "print(f\"After adjustment, New Train PL median: {df_train.loc[df_train['sat_type'] == 1, 'cn0_new'].median()}\")\n",
    "print(f\"After adjustment, New Train GPS median: {df_train.loc[df_train['sat_type'] == 0, 'cn0_new'].median()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d82329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (171431, 10, 5) (171431,)\n",
      "Test shape: (79750, 10, 5) (79750,)\n",
      "Epoch [1/10], Loss: 0.2691\n",
      "Epoch [2/10], Loss: 0.2413\n",
      "Epoch [3/10], Loss: 0.2347\n",
      "Epoch [4/10], Loss: 0.2281\n",
      "Epoch [5/10], Loss: 0.2118\n",
      "Epoch [6/10], Loss: 0.1826\n",
      "Epoch [7/10], Loss: 0.1726\n",
      "Epoch [8/10], Loss: 0.1658\n",
      "Epoch [9/10], Loss: 0.1616\n",
      "Epoch [10/10], Loss: 0.1580\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     LOS (0)       0.91      0.97      0.94     35189\n",
      "    NLOS (1)       0.97      0.93      0.95     44561\n",
      "\n",
      "    accuracy                           0.95     79750\n",
      "   macro avg       0.94      0.95      0.95     79750\n",
      "weighted avg       0.95      0.95      0.95     79750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Dataset Preparation\n",
    "# ----------------------------\n",
    "features = [\"cn0_new\", \"elevation\", \"pseudorange_residual\", \"sat_type\"]\n",
    "target = \"multipath\"\n",
    "SEQ_LEN = 10  # sequence length (10 epochs per satellite)\n",
    "\n",
    "# Encode sv_id\n",
    "le = LabelEncoder()\n",
    "df_train[\"sv_id_enc\"] = le.fit_transform(df_train[\"sv_id\"])\n",
    "df_test[\"sv_id_enc\"]  = le.transform(df_test[\"sv_id\"])\n",
    "features_with_id = features + [\"sv_id_enc\"]\n",
    "\n",
    "def make_sequences(df, seq_len):\n",
    "    X, y = [], []\n",
    "    for sat_id, sat_df in df.groupby(\"sv_id\"):\n",
    "        sat_df = sat_df.sort_values(\"gps_time\")\n",
    "        arr = sat_df[features_with_id].values\n",
    "        labels = sat_df[target].values\n",
    "        for i in range(len(sat_df) - seq_len + 1):\n",
    "            X.append(arr[i:i+seq_len])\n",
    "            y.append(labels[i+seq_len-1])  # label = last in window\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)\n",
    "\n",
    "X_train, y_train = make_sequences(df_train, SEQ_LEN)\n",
    "X_test, y_test   = make_sequences(df_test, SEQ_LEN)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. PyTorch Dataset + DataLoader\n",
    "# ----------------------------\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X)\n",
    "        self.y = torch.tensor(y)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_loader = DataLoader(SeqDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(SeqDataset(X_test, y_test), batch_size=64, shuffle=False)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. LSTM Model\n",
    "# ----------------------------\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=1, num_classes=2):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)               # out: [batch, seq, hidden]\n",
    "        out = out[:, -1, :]                 # take last time step\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(input_dim=X_train.shape[2]).to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Training Loop\n",
    "# ----------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Evaluation\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        y_true.extend(y_batch.numpy())\n",
    "        y_pred.extend(preds)\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"LOS (0)\", \"NLOS (1)\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b7abc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 1653 LOS and 9419 NLOS in real data.\n",
      "\n",
      "ğŸ” GPS Signals:\n",
      "  â–¶ Total           : 4910\n",
      "  â–¶ Predicted LOS   : 229 (4.7%)\n",
      "  â–¶ Predicted NLOS  : 4681 (95.3%)\n",
      "\n",
      "ğŸ” PL Signals:\n",
      "  â–¶ Total           : 1376\n",
      "  â–¶ Predicted LOS   : 230 (16.7%)\n",
      "  â–¶ Predicted NLOS  : 1146 (83.3%)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1. Ensure cn0_new exists      real dataset import\n",
    "# ----------------------------\n",
    "if \"cn0_new\" not in df_real.columns and \"cn0\" in df_real.columns:\n",
    "    df_real[\"cn0_new\"] = df_real[\"cn0\"]\n",
    "\n",
    "df_real[\"sv_id_enc\"] = -1  # default for unknown satellites\n",
    "known_mask = df_real[\"sv_id\"].isin(le.classes_)\n",
    "df_real.loc[known_mask, \"sv_id_enc\"] = le.transform(df_real.loc[known_mask, \"sv_id\"])\n",
    "\n",
    "# 3. Now define features_with_id (must include sv_id_enc)\n",
    "features_with_id = [\"cn0_new\", \"elevation\", \"pseudorange_residual\", \"sat_type\", \"sv_id_enc\"]\n",
    "\n",
    "# 4. Remove rows with missing values\n",
    "df_real_filtered = df_real.dropna(subset=features_with_id).copy()\n",
    "\n",
    "# Encode sv_id (must use the SAME encoder as training)\n",
    "# df_real_filtered[\"sv_id_enc\"] = le.transform(df_real_filtered[\"sv_id\"])\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Build sequences (no target)\n",
    "# ----------------------------\n",
    "def make_sequences_inference(df, seq_len):\n",
    "    seqs, idx_map = [], []  # keep track of row indices for mapping back\n",
    "    for sat_id, sat_df in df.groupby(\"sv_id\"):\n",
    "        sat_df = sat_df.sort_values(\"gps_time\")\n",
    "        arr = sat_df[features_with_id].values\n",
    "        for i in range(len(sat_df) - seq_len + 1):\n",
    "            seqs.append(arr[i:i+seq_len])\n",
    "            idx_map.append(sat_df.index[i+seq_len-1])  # map prediction to last row\n",
    "    return np.array(seqs, dtype=np.float32), idx_map\n",
    "\n",
    "X_real_seq, idx_map = make_sequences_inference(df_real_filtered, SEQ_LEN)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Run LSTM model inference\n",
    "# ----------------------------\n",
    "model.eval()\n",
    "y_real_pred = []\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_real_seq).to(device)\n",
    "    outputs = model(X_tensor)\n",
    "    preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "    y_real_pred.extend(preds)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Add predictions back\n",
    "# ----------------------------\n",
    "df_real_filtered[\"predicted_multipath\"] = np.nan  # init column\n",
    "for idx, pred in zip(idx_map, y_real_pred):\n",
    "    df_real_filtered.loc[idx, \"predicted_multipath\"] = pred  # 0=LOS, 1=NLOS\n",
    "\n",
    "print(f\"Predicted {np.sum(df_real_filtered['predicted_multipath']==0)} LOS \"\n",
    "      f\"and {np.sum(df_real_filtered['predicted_multipath']==1)} NLOS in real data.\")\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Per satellite type summary\n",
    "# ----------------------------\n",
    "for sat_label, sat_name in zip([0, 1], [\"GPS\", \"PL\"]):\n",
    "    df_sat = df_real_filtered[df_real_filtered[\"sat_type\"] == sat_label]\n",
    "    los_count = (df_sat[\"predicted_multipath\"] == 0).sum()\n",
    "    nlos_count = (df_sat[\"predicted_multipath\"] == 1).sum()\n",
    "    total = df_sat[\"predicted_multipath\"].notna().sum()\n",
    "\n",
    "    los_percent = 100 * los_count / total if total > 0 else 0\n",
    "    nlos_percent = 100 * nlos_count / total if total > 0 else 0\n",
    "\n",
    "    print(f\"\\nğŸ” {sat_name} Signals:\")\n",
    "    print(f\"  â–¶ Total           : {total}\")\n",
    "    print(f\"  â–¶ Predicted LOS   : {los_count} ({los_percent:.1f}%)\")\n",
    "    print(f\"  â–¶ Predicted NLOS  : {nlos_count} ({nlos_percent:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f46751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 1653 LOS and 9419 NLOS in real data.\n",
      "0        NaN\n",
      "1        1.0\n",
      "2        NaN\n",
      "3        NaN\n",
      "4        1.0\n",
      "        ... \n",
      "12609    1.0\n",
      "12610    1.0\n",
      "12611    0.0\n",
      "12612    0.0\n",
      "12613    0.0\n",
      "Name: predicted_multipath, Length: 11243, dtype: float64\n",
      "\n",
      "ğŸ” GPS Signals:\n",
      "  â–¶ Total           : 4910\n",
      "  â–¶ Predicted LOS   : 229 (4.7%)\n",
      "  â–¶ Predicted NLOS  : 4681 (95.3%)\n",
      "\n",
      "ğŸ” PL Signals:\n",
      "  â–¶ Total           : 1376\n",
      "  â–¶ Predicted LOS   : 230 (16.7%)\n",
      "  â–¶ Predicted NLOS  : 1146 (83.3%)\n"
     ]
    }
   ],
   "source": [
    "df_real_filtered[\"predicted_multipath\"] = np.nan  # init column\n",
    "for idx, pred in zip(idx_map, y_real_pred):\n",
    "    df_real_filtered.loc[idx, \"predicted_multipath\"] = pred  # 0=LOS, 1=NLOS\n",
    "\n",
    "print(f\"Predicted {np.sum(df_real_filtered['predicted_multipath']==0)} LOS \"\n",
    "      f\"and {np.sum(df_real_filtered['predicted_multipath']==1)} NLOS in real data.\")\n",
    "\n",
    "print(df_real_filtered['predicted_multipath'])\n",
    "# ----------------------------\n",
    "# 5. Per satellite type summary\n",
    "# ----------------------------\n",
    "for sat_label, sat_name in zip([0, 1], [\"GPS\", \"PL\"]):\n",
    "    df_sat = df_real_filtered[df_real_filtered[\"sat_type\"] == sat_label]\n",
    "    los_count = (df_sat[\"predicted_multipath\"] == 0).sum()\n",
    "    nlos_count = (df_sat[\"predicted_multipath\"] == 1).sum()\n",
    "    total = df_sat[\"predicted_multipath\"].notna().sum()\n",
    "\n",
    "    los_percent = 100 * los_count / total if total > 0 else 0\n",
    "    nlos_percent = 100 * nlos_count / total if total > 0 else 0\n",
    "\n",
    "    print(f\"\\nğŸ” {sat_name} Signals:\")\n",
    "    print(f\"  â–¶ Total           : {total}\")\n",
    "    print(f\"  â–¶ Predicted LOS   : {los_count} ({los_percent:.1f}%)\")\n",
    "    print(f\"  â–¶ Predicted NLOS  : {nlos_count} ({nlos_percent:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b68f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: CSV\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "df_real_filtered.to_csv(\"real_with_predicted_multipath_LSTM.csv\", index=False)\n",
    "print(\"âœ… Saved: CSV\")\n",
    "#è¿™ä¸ªæ˜¯ä½¿ç”¨ lstmæ¨¡å‹è·‘è·‘å®Œçš„çœŸå®æ•°æ®åˆ†ç±»ç»“æœï¼Œæ‰€ä»¥ æˆ‘ä»¬éœ€è¦æŠŠç»“æœè¾“å…¥å›ä½ç½®è§£ç®— ç„¶å å’Œ å®šä½å¯¹æ¯” "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
